4.0版本相较于3.0版本，只有工程上的一点改进，整体思想与3.0一模一样，整个算法实现的变动在于key_file的读出和写入都是采用二进制的方式。
我们取32位整型作为二进制buffer数组的基本格式，只有格式固定，才能进行二进制整块读和写。总体来说，速度确实提升不少。

算法的整体思想和3.0版本相同： 1.遍历原始文件, 利用count-min统计每个组的rough size， 同时生成中间文件key_file。
                          2.人为设置一个阈值，遍历key_file,如果rough group size大于阈值，则是大组，如果小于，则是小组。这里采用和2.0版本一样的方法，
                          将rough size作为精确size建立输出索引。不过，只对大组建立索引，小组不作处理。
                          3.遍历原始文件， 如果在输出索引中有匹配，则是big group，则根据输出索引输出big groups。小组整个过程都没有进行处理，当时的想
                          法是：小组的size小，可以很方便的读入内存，将小组的groupBy操作交给后续的aggregate操作

问题：由于二进制buffer是整型数组，所以只适合key是整型的数据集，局限性很强。